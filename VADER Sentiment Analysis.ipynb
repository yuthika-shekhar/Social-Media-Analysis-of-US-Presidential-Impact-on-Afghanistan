{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "### Data Mining Project \n",
    "\n",
    "### Project: US Presidential Impact on Afghanistan\n",
    "### Team Members: Aditya Taori and Yuthika Shekhar\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing Libraries\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "import plotly.express as px\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from matplotlib.cbook import flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordcloud(text_col,figure_size = (15.0,10.0),title=None,title_size = 30):\n",
    "    text = \" \".join(text_col.values.tolist())\n",
    "    wordcloud = WordCloud(background_color=\"white\",random_state=42,width = 500,height = 500).generate(text)\n",
    "\n",
    "    # Display the generated image:\n",
    "    # the matplotlib way:\n",
    "    plt.figure(figsize = figure_size)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    return wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Ngrams Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams_frequency_chart(df,text_col,ngram_val):\n",
    "    y = \" \".join(df[text_col].values.tolist())\n",
    "    tokenization = nltk.word_tokenize(y)\n",
    "    ngram_dataset = ngrams(tokenization,ngram_val)\n",
    "    ngram_count = Counter(ngram_dataset)\n",
    "    freq_uni_df = pd.DataFrame(ngram_count.most_common(30))\n",
    "    freq_uni_df.columns = ['Ngrams','Count']\n",
    "    return freq_uni_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(text):\n",
    "    text = str(text).lower()  #Lowercasing the text\n",
    "    text = re.sub('\\[.*?\\]', '', text)   \n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)  #Removing Hyperlinks\n",
    "    text = re.sub('<.*?>+', '', text)  #Removing HTML Tags\n",
    "    table=str.maketrans('','',string.punctuation)  #Removing Punctuations\n",
    "    text =text.translate(table) \n",
    "    text = re.sub('\\n', '', text)  #Removing Newline Character\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)  #Removing Non alphas character \n",
    "    text_tokens = word_tokenize(text) #Tokenizing the data\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')] #Removing Stopwords\n",
    "    return \" \".join(tokens_without_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Input Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"E:/UOR Notes/Data Mining/Assignments/US Presidential Impact/Output_Files/CSV Files/Osama Bin Laden Killed/\"\n",
    "tweets_file = \"Osama bin Laden Killed.csv\"  #Tweets Dataset\n",
    "users_file = \"User_Info_Osama bin Laden Killed.csv\"  #Users Dataset\n",
    "tweet_file_path = input_dir+tweets_file \n",
    "user_file_path = input_dir+users_file\n",
    "\n",
    "output_dir = \"E:/UOR Notes/Data Mining/Assignments/US Presidential Impact/Output_Files/\"  #Directory to save output files\n",
    "visualization_folder = \"Visualization Results/\"  \n",
    "event_name = \"Osama Bin Laden Killed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Tweets and User Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data = pd.read_csv(tweet_file_path)  #Reading Tweets Dataset \n",
    "users_data = pd.read_csv(user_file_path)    #Reading Users Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating datetime object for Tweets Published Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_val = tweets_data.created_at.str.replace(\".000Z\",\"\")   \n",
    "time_val = time_val.str.replace(\"T\",\" \")\n",
    "tweets_data[\"Published_Date_Format\"] =pd.to_datetime(time_val,format = \"%Y-%m-%d %H:%M:%S\")\n",
    "tweets_data[\"Published_Date\"] = tweets_data[\"Published_Date_Format\"].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Timeline Distribution for Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (15,8))\n",
    "timeline_sentiment_distribution = tweets_data.groupby([\"Published_Date\"])[\"public_metrics.retweet_count\"].count().plot(ax = ax)\n",
    "#timeline_sentiment_distribution.save()\n",
    "plt.title(\"Tweets Timeline Distribution\")\n",
    "plt.xlabel(\"Tweets Published Date\")\n",
    "plt.ylabel(\"Count of Tweets\")\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Timeline_Distribution.png\"\n",
    "plt.savefig(outfile_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Wordcloud of Original Tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = create_wordcloud(tweets_data.text,title= event_name+\"_Wordcloud\")\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Wordcloud.png\"\n",
    "wc.to_file(outfile_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Ngrams Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_df = ngrams_frequency_chart(tweets_data,\"text\",ngram_val=1)\n",
    "bigram_df = ngrams_frequency_chart(tweets_data,\"text\",ngram_val=2)\n",
    "trigram_df = ngrams_frequency_chart(tweets_data,\"text\",ngram_val=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Unigram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "uni_df.plot.bar(x=\"Ngrams\",y=\"Count\",title= \"Unigram Frequency\")\n",
    "plt.xlabel(\"Unigrams\")\n",
    "plt.ylabel(\"Count\")\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Unigram_Frequency.png\"\n",
    "plt.savefig(outfile_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Bigram Frequency Bar Chart  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "bigram_df.plot.bar(x=\"Ngrams\",y=\"Count\",title= \"Bigram Frequency\")\n",
    "plt.xlabel(\"Bigrams\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Bigram_Frequency.png\"\n",
    "plt.savefig(outfile_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Trigram Frequency Bar Chart  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "trigram_df.plot.bar(x=\"Ngrams\",y=\"Count\",title= \"Trigram Frequency\")\n",
    "plt.xlabel(\"Trigrams\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Trigram_Frequency.png\"\n",
    "plt.savefig(outfile_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Hashtags and Usertags from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data[\"user_tags\"] = tweets_data[\"text\"].str.findall('@[a-zA-Z0-9_]+')\n",
    "tweets_data[\"hashtags\"] = tweets_data[\"text\"].str.findall('#[a-zA-Z0-9_]+')\n",
    "\n",
    "hashtags = tweets_data[\"hashtags\"].tolist()\n",
    "list_hashtags={'Hashtags':[hashtags]}\n",
    "for a,i in list_hashtags.items() :\n",
    "    hashtags_df=pd.DataFrame.from_dict(dict(Counter([*flatten(i)])), orient ='index').reset_index().rename(columns ={'index':a,0:str(a)+'_count'})\n",
    "sorted_hc = hashtags_df.sort_values([\"Hashtags_count\"],ascending=False)\n",
    "\n",
    "sorted_hc =sorted_hc.reset_index()\n",
    "sorted_hc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = tweets_data[\"user_tags\"].tolist()\n",
    "list_tags={'UserTags':[tags]}\n",
    "for a,i in list_tags.items() :\n",
    "    user=pd.DataFrame.from_dict(dict(Counter([*flatten(i)])), orient ='index').rename(columns ={'index':a,0:str(a)+'_count'})\n",
    "sorted_tags = user.sort_values([\"UserTags_count\"],ascending=False)\n",
    "sorted_tags =sorted_tags.reset_index() \n",
    "sorted_tags.columns = [\"Tags\",\"Count\"]\n",
    "sorted_tags[\"Tags_Proporton\"] = sorted_tags[\"Count\"]/sorted_tags.sum().Count\n",
    "sorted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tags =sorted_tags.sum().Count\n",
    "total_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting  Top 20 Hashtags from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sorted_hc.iloc[0:20].plot.bar(x=\"Hashtags\",y=\"Hashtags_count\", \n",
    "                              color = \"Orange\",\n",
    "                              rot = 90,\n",
    "                              figsize=(10,5),\n",
    "                              title = \"Top 20 Hashtags\",\n",
    "                              xlabel =\" Hashtags\",\n",
    "                              ylabel = \"Hashtags Count\")\n",
    "fig = ax.get_figure()\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Top_20_Hashtags.png\"\n",
    "fig.savefig(outfile_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Top 20 Usertags from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sorted_tags.iloc[0:20].plot.bar(x=\"Tags\",y=\"Count\", \n",
    "                              color = \"Purple\",\n",
    "                              rot = 90,\n",
    "                              figsize=(10,5),\n",
    "                              title = \"Top 20 Usertags\",\n",
    "                              xlabel = \"Usertags\",\n",
    "                              ylabel = \"Usertags Count\")\n",
    "fig = ax.get_figure()\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Top_20_Usertags.png\"\n",
    "fig.savefig(outfile_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Data Cleaning on Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = tweets_data[\"text\"].apply(data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data[\"cleaned_text\"] = cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud of Cleaned Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = create_wordcloud(tweets_data.cleaned_text,title= event_name+\"_Cleaned Data Wordcloud\")\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Cleaned_Data_Wordcloud.png\"\n",
    "wc.to_file(outfile_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned Data Ngrams dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_uni_df = ngrams_frequency_chart(tweets_data,\"cleaned_text\",ngram_val=1)\n",
    "cleaned_bigram_df = ngrams_frequency_chart(tweets_data,\"cleaned_text\",ngram_val=2)\n",
    "cleaned_trigram_df = ngrams_frequency_chart(tweets_data,\"cleaned_text\",ngram_val=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned Unigram Frequency Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "cleaned_uni_df.plot.bar(x=\"Ngrams\",y=\"Count\",title= \"Unigram Frequency\")\n",
    "plt.xlabel(\"Unigrams\")\n",
    "plt.ylabel(\"Count\")\n",
    "#plt.show()\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Cleaned_Unigram_Frequency.png\"\n",
    "plt.savefig(outfile_name)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned Bigram Frequency Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "cleaned_bigram_df.plot.bar(x=\"Ngrams\",y=\"Count\",title= \"Bigram Frequency\")\n",
    "plt.xlabel(\"Bigrams\")\n",
    "plt.ylabel(\"Count\")\n",
    "#plt.show()\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Cleaned_Bigram_Frequency.png\"\n",
    "plt.savefig(outfile_name)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned Trigram Frequency Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "cleaned_trigram_df.plot.bar(x=\"Ngrams\",y=\"Count\",title= \"Trigram Frequency\")\n",
    "plt.xlabel(\"Trigrams\")\n",
    "plt.ylabel(\"Count\")\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Cleaned_Trigram_Frequency.png\"\n",
    "plt.savefig(outfile_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Sentiment Analysis on tweets with a threshold of 0.05 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "tweets_data['score'] = tweets_data['text'].apply(lambda review: sid.polarity_scores(review))\n",
    "tweets_data['compound'] = tweets_data['score'].apply(lambda scores_values: scores_values['compound'])\n",
    "compound = tweets_data['Sentiments'] = tweets_data['compound'].apply(lambda value : 'pos' if value > 0.05 else \n",
    "                                                   ('neg' if value <= -0.05 else 'neutral'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Tweets Dataset and Users Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_id = users_data['author_id_str'].unique().tolist()\n",
    "#author_id = users_data['Str_id'].unique().tolist()\n",
    "len(author_id)\n",
    "\n",
    "users_data = users_data.drop_duplicates(subset=['author_id_str'])\n",
    "users_data.shape\n",
    "\n",
    "#join = pd.merge(tweets_data,users_data,on='author_id_str',how='left')\n",
    "join = pd.merge(tweets_data,users_data,left_on='id_str',right_on='author_id_str',how='left')\n",
    "\n",
    "join.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the sentiment counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_count = join.groupby(\"Sentiments\")[\"compound\"].count()\n",
    "sentiment_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join.to_csv(event_name+\"Sentiment_Analysis_Output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the sentiment Proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = sum(sentiment_count)\n",
    "\n",
    "perc = sentiment_count/add * 100\n",
    "perc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Distribution Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile_name = output_dir + visualization_folder+event_name+\"_Sentiment_Distribution.png\"\n",
    "sns.barplot(x = perc.index,y=perc.values.tolist())\n",
    "plt.xlabel(\"Sentiments\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.title(event_name+\"_Sentiment Distribution\")\n",
    "plt.savefig(outfile_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngrams Dataframe for Positive and Negative Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = join[join[\"Sentiments\"]==\"pos\"]\n",
    "neg_df = join[join[\"Sentiments\"]==\"neg\"]\n",
    "pos_uni_df = ngrams_frequency_chart(pos_df,\"cleaned_text\",ngram_val=1)\n",
    "pos_bigram_df = ngrams_frequency_chart(pos_df,\"cleaned_text\",ngram_val=2)\n",
    "pos_trigram_df = ngrams_frequency_chart(pos_df,\"cleaned_text\",ngram_val=3)\n",
    "neg_uni_df = ngrams_frequency_chart(neg_df,\"cleaned_text\",ngram_val=1)\n",
    "neg_bigram_df = ngrams_frequency_chart(neg_df,\"cleaned_text\",ngram_val=2)\n",
    "neg_trigram_df = ngrams_frequency_chart(neg_df,\"cleaned_text\",ngram_val=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Sentiments Unigram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "pos_uni_df.plot.bar(x=\"Ngrams\",y=\"Count\",title= \"Unigram Frequency\")\n",
    "plt.xlabel(\"Unigram\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Positive_Sentiment_Unigram_Frequency.png\"\n",
    "plt.savefig(outfile_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Sentiments Bigram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "pos_bigram_df.plot.bar(x=\"Ngrams\",y=\"Count\",title= \"Bigram Frequency\")\n",
    "plt.xlabel(\"Bigram\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Positive_Sentiment_Bigram_Frequency.png\"\n",
    "plt.savefig(outfile_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Sentiments Trigram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "pos_trigram_df.plot.bar(x=\"Ngrams\",y=\"Count\",title= \"Trigram Frequency\")\n",
    "plt.xlabel(\"Trigram\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Positive_Sentiment_Trigram_Frequency.png\"\n",
    "plt.savefig(outfile_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Sentiments Unigram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "neg_uni_df.plot.bar(x=\"Ngrams\",y=\"Count\",title= \"Unigram Frequency\")\n",
    "plt.xlabel(\"Unigram\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Negative_Sentiment_Unigram_Frequency.png\"\n",
    "plt.savefig(outfile_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Sentiments Bigram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "neg_bigram_df.plot.bar(x=\"Ngrams\",y=\"Count\",title= \"Bigram Frequency\")\n",
    "plt.xlabel(\"Bigram\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Negative_Sentiment_Bigram_Frequency.png\"\n",
    "plt.savefig(outfile_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Sentiment Trigram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "neg_trigram_df.plot.bar(x=\"Ngrams\",y=\"Count\",title= \"Trigram Frequency\")\n",
    "plt.xlabel(\"Trigram\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Negative_Sentiment_Trigram_Frequency.png\"\n",
    "plt.savefig(outfile_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Sentiments Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_wc = create_wordcloud(pos_df.cleaned_text,title= event_name+\"_Positive_Sentiments_Wordcloud\")\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Positive_Sentiments_Wordcloud.png\"\n",
    "pos_wc.to_file(outfile_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Sentiments Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_wc = create_wordcloud(neg_df.cleaned_text,title= event_name+\"_Negative_Sentiments_Wordcloud\")\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Negative_Sentiments_Wordcloud.png\"\n",
    "neg_wc.to_file(outfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_val = join.created_at_x.str.replace(\".000Z\",\"\")\n",
    "time_val = time_val.str.replace(\"T\",\" \")\n",
    "join[\"Published_Date_Format\"] =pd.to_datetime(time_val,format = \"%Y-%m-%d %H:%M:%S\")\n",
    "join[\"Published_Date\"] = join[\"Published_Date_Format\"].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiments Timeline Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (15,8))\n",
    "timeline_sentiment_distribution = join.groupby([\"Published_Date\",\"Sentiments\"])[\"Sentiments\"].count().unstack().plot(ax = ax)\n",
    "#timeline_sentiment_distribution.save()\n",
    "ax.set(xlabel = \"Published Date\",ylabel= \"Count\",title=\"Timeline Distribution of Sentiment\" )\n",
    "outfile_name = output_dir + visualization_folder+event_name+\"_Sentiments_Timeline_Distribution.png\"\n",
    "plt.savefig(outfile_name)\n",
    "#timeline_sentiment_distribution\n",
    "#for key, grp in timeline_sentiment_distribution:\n",
    "#    ax.plot(grp['Published_Date'], grp['Sentiments'], label=key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
